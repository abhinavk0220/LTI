{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7f2a8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "from langchain_community.vectorstores import FAISS  \n",
    "from langchain_core.prompts import ChatPromptTemplate  \n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser \n",
    "from langchain_core.runnables import RunnablePassthrough  \n",
    "from langchain_ollama import ChatOllama,OllamaEmbeddings  \n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory  \n",
    "from langchain_core.runnables import RunnableWithMessageHistory  \n",
    "from langchain_core.tools import tool  \n",
    "from langchain_core.messages import AIMessage, HumanMessage  \n",
    "from langchain_community.retrievers import BM25Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "adb4c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 docs.\n",
      "Sample content: Incident #001 | User=johns | Alert=Multiple failed SSH logins | SourceIP=10.1.1.9 | Host=SRV-LNX-01 | OS=Ubuntu 20 | MITRE=T1110 | Severity=High | Resolution=Blocked source IP; Reset password; Enabled\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"mistral\", temperature=0.5)\n",
    "\n",
    "\n",
    "\n",
    "loader = TextLoader(\"security_incidents.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load() \n",
    "\n",
    "print(f\"Loaded {len(docs)} docs.\")\n",
    "print(\"Sample content:\", docs[0].page_content[:200]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17d0aba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 40 chunks.\n",
      "Chunk 1 (len 205 chars): Incident #001 | User=johns | Alert=Multiple failed SSH logins | SourceIP=10.1.1.9 | Host=SRV-LNX-01 ...\n",
      "Chunk 2 (len 221 chars): Incident #002 | User=markp | Alert=Suspicious PowerShell encoded command detected | Host=WKS-22 | OS...\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)  \n",
    "splits = splitter.split_documents(docs) \n",
    "\n",
    "print(f\"Created {len(splits)} chunks.\") \n",
    "for i, chunk in enumerate(splits[:2]):\n",
    "    print(f\"Chunk {i+1} (len {len(chunk.page_content)} chars): {chunk.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae631361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built with 40 vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"nomic-embed-text:latest\")  \n",
    "vectorstore = FAISS.from_documents(splits, embeddings)  \n",
    "\n",
    "retriever = vectorstore.as_retriever(k=4)  \n",
    "\n",
    "print(f\"Index built with {len(splits)} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7060349",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(f\"\"\" You are a Security Incident Assistant that\n",
    "                helps IT analysts to Recommend resolutions, Retrieve similar past incidents,\n",
    "        Recall analyst-specific preferences across sessions\n",
    ", Extract important entities (IPs, OS, MITRE tags)\n",
    ", \\tProvide enriched threat analysis based on historical data.\n",
    "                                          Ensure the responses doesn't consist of the prompt template.\n",
    "Use the following context to answer the question.\n",
    "                                          ENsure the response is in JSON format as per the schema: {json_parser.get_format_instructions()}\n",
    " : Context: {{context}}\\nQuestion:  {{question}}\\nAnswer:  \"\"\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d6ac2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import rank_bm25\n",
    "class HybridRetriever:\n",
    "    def __init__(self, dense_retriever, sparse_retriever, k=4):\n",
    "        self.dense_retriever = dense_retriever\n",
    "        self.sparse_retriever = sparse_retriever\n",
    "        self.k = k\n",
    "\n",
    "    def invoke(self, query: str) -> list[Document]:\n",
    "        dense_results = self.dense_retriever.invoke(query)\n",
    "        sparse_results = self.sparse_retriever.invoke(query)\n",
    "\n",
    "        \n",
    "        all_docs = {doc.page_content: doc for doc in dense_results + sparse_results}\n",
    "        return list(all_docs.values())[:self.k]\n",
    "    \n",
    "bm2=BM25Retriever.from_documents(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d62cf45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetriever(retriever, bm2, k=4)\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "hybrid_runnable = RunnableLambda(lambda q: hybrid_retriever.invoke(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e38a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "# Initialize Redis connection\n",
    "r = redis.StrictRedis(host='localhost', port=6379, db=0, decode_responses=True)\n",
    "\n",
    "def cache_key(prompt: str) -> str:\n",
    "    return hashlib.md5(prompt.encode()).hexdigest()\n",
    "\n",
    "def get_kb_result(query: str):\n",
    "    key = cache_key(query)\n",
    "    cached_result = r.get(key) \n",
    "    \n",
    "    if cached_result:\n",
    "        print(\"Cache hit!\")\n",
    "        return json.loads(cached_result)\n",
    "    else:\n",
    "        print(\"Cache miss! Running RAG chain.\")\n",
    "        \n",
    "        \n",
    "        result = hybrid_retriever.invoke(query) \n",
    "        \n",
    "        \n",
    "        r.set(key, json.dumps(result), ex=3600) \n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28516598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache miss! Running RAG chain (with enrichment & scoring).\n",
      "Response:  {'recommended_resolution': 'Conduct a comprehensive network scan to identify and block suspicious IPs; Alert the network team for further investigation.', 'similar_past_incidents': [{'source': 'security_incidents.txt', 'snippet': 'Incident #034 | User=rakesh | Alert=Outbound traffic to known malicious IP | SourceIP=10.22.3.9 | Host=SRV-DB01 | OS=CentOS 7 | MITRE=T1071 | Severity=High | Resolution=Blocked traffic; Conducted IOC scan.'}, {'source': 'security_incidents.txt', 'snippet': 'Incident #012 | User=kishor | Alert=Detected network port scanning | SourceIP=172.22.9.54 | Host=SRV-WIN-02 | OS=Windows Server 2019 | MITRE=T1046 | Severity=High | Resolution=Blocked IP; Alerted network team.'}], 'entities': {'IPs': ['10.22.3.9', '172.22.9.54'], 'OS': ['Windows Server', 'CentOS', 'Windows'], 'Hostnames': ['SRV-DB01', 'SRV-WIN-02'], 'MITRE': ['T1046', 'T1071'], 'Severity': ['High']}, 'user_id': 'analyst500'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import ipaddress\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# --- Entity extraction utilities ---\n",
    "_ip_re = re.compile(r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\")\n",
    "_mitre_re = re.compile(r\"\\bT\\d{4}\\b\", re.IGNORECASE)\n",
    "_severity_re = re.compile(r\"\\b(Critical|High|Medium|Low)\\b\", re.IGNORECASE)\n",
    "_hostname_re = re.compile(r\"\\b[A-Za-z0-9][-A-Za-z0-9_.]{1,62}\\b\")  # loose hostname token matcher\n",
    "\n",
    "# common OS tokens to look for in text\n",
    "_OS_KEYWORDS = [\n",
    "    \"Windows Server\", \"Windows\", \"CentOS\", \"RedHat\", \"Red Hat\", \"Ubuntu\",\n",
    "    \"Debian\", \"Fedora\", \"macOS\", \"mac os\", \"Windows 10\", \"Windows 11\",\n",
    "    \"Windows Server 2019\", \"Win11\", \"Win10\"\n",
    "]\n",
    "_bruteforce_indicators = [\n",
    "    \"failed login\", \"failed logins\", \"brute force\", \"brute-force\", \"throttled login\",\n",
    "    \"password spray\", \"multiple failed\", \"account lockout\"\n",
    "]\n",
    "_powershell_indicators = [\"powershell\", \"encoded command\", \"Invoke-Expression\", \"IEX\", \"-EncodedCommand\"]\n",
    "\n",
    "\n",
    "def _clean_ips(ip_candidates):\n",
    "    ips = []\n",
    "    for ip in ip_candidates:\n",
    "        try:\n",
    "            # filter out bogus like 999.999.999.999\n",
    "            ipaddress.ip_address(ip)\n",
    "            ips.append(ip)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return sorted(set(ips))\n",
    "\n",
    "\n",
    "def extract_entities(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract IPs, OS mentions, hostnames, MITRE technique codes, Severity from a string.\n",
    "    Returns standardized dict.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {\"IPs\": [], \"OS\": [], \"Hostnames\": [], \"MITRE\": [], \"Severity\": []}\n",
    "\n",
    "    ips = _clean_ips(_ip_re.findall(text))\n",
    "    mitre = sorted({m.upper() for m in _mitre_re.findall(text)})\n",
    "    severity = sorted(set([s.capitalize() for s in _severity_re.findall(text)]))\n",
    "\n",
    "    # OS detection - look for any token occurrences (case-insensitive)\n",
    "    os_found = []\n",
    "    lower = text.lower()\n",
    "    for tok in _OS_KEYWORDS:\n",
    "        if tok.lower() in lower and tok not in os_found:\n",
    "            os_found.append(tok)\n",
    "\n",
    "    # Hostnames: approximate by searching tokens that look like hostnames and not common words/OS\n",
    "    hostnames = []\n",
    "    for token in _hostname_re.findall(text):\n",
    "        t = token.strip()\n",
    "        if len(t) < 3 or t.lower() in [o.lower() for o in _OS_KEYWORDS]:\n",
    "            continue\n",
    "        # crude heuristic: include tokens that have a dash or uppercase-with-digits like WKS-22, SRV01 etc\n",
    "        if \"-\" in t or re.search(r\"[A-Z]{2,}\\d*\", t) or re.search(r\"\\d{2,}\", t):\n",
    "            hostnames.append(t)\n",
    "    hostnames = sorted(set(hostnames))\n",
    "\n",
    "    return {\"IPs\": ips, \"OS\": os_found, \"Hostnames\": hostnames, \"MITRE\": mitre, \"Severity\": severity}\n",
    "\n",
    "\n",
    "# --- Threat enrichment tool (local) ---\n",
    "def threat_enrichment(entities: dict, docs: list) -> dict:\n",
    "    \"\"\"\n",
    "    Produce lightweight enrichment: mark known-malicious IPs (if referenced in past incidents),\n",
    "    list related incidents for MITRE/hosts, and surface relevant doc snippets.\n",
    "    \"\"\"\n",
    "    ips = entities.get(\"IPs\", [])\n",
    "    mitres = entities.get(\"MITRE\", [])\n",
    "    hosts = entities.get(\"Hostnames\", [])\n",
    "\n",
    "    related_incidents = []\n",
    "    malicious_ips = []\n",
    "    snippets = []\n",
    "\n",
    "    for d in docs:\n",
    "        pc = d.page_content\n",
    "        # collect snippets that contain any entity\n",
    "        if any(x in pc for x in ips + mitres + hosts):\n",
    "            snippets.append(pc[:400])\n",
    "\n",
    "        # if IP present in doc, treat it as evidence of maliciousness (local heuristic)\n",
    "        for ip in ips:\n",
    "            if ip in pc and ip not in malicious_ips:\n",
    "                malicious_ips.append(ip)\n",
    "\n",
    "        # add incidents that mention MITREs or hosts\n",
    "        if any(m in pc for m in mitres) or any(h in pc for h in hosts):\n",
    "            related_incidents.append({\"source\": d.metadata.get(\"source\"), \"snippet\": pc[:300]})\n",
    "\n",
    "    return {\n",
    "        \"malicious_IPs\": malicious_ips,\n",
    "        \"related_incidents\": related_incidents,\n",
    "        \"snippets\": snippets[:10],\n",
    "        \"note\": \"Enrichment is local (based on retrieved KB). For external feeds use IOC feeds.\"\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Threat scoring logic ---\n",
    "def compute_threat_score(entities: dict, docs: list) -> tuple[int, dict]:\n",
    "    \"\"\"\n",
    "    Custom scoring:\n",
    "      - MITRE tags: each tag adds 12 (up to cap)\n",
    "      - Severity text: Critical=35, High=25, Medium=12, Low=5 (take max if multiple)\n",
    "      - Malicious IP presence: +20\n",
    "      - Suspicious PowerShell activity: +15\n",
    "      - Brute-force indicators: +15\n",
    "    Returns (score 0-100, breakdown)\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    breakdown = {}\n",
    "\n",
    "    # MITRE\n",
    "    mitres = entities.get(\"MITRE\", [])\n",
    "    mitre_score = min(40, len(mitres) * 12)\n",
    "    breakdown[\"mitre_count\"] = len(mitres)\n",
    "    breakdown[\"mitre_score\"] = mitre_score\n",
    "    score += mitre_score\n",
    "\n",
    "    # Severity\n",
    "    sev_map = {\"Critical\": 35, \"High\": 25, \"Medium\": 12, \"Low\": 5}\n",
    "    sevs = entities.get(\"Severity\", [])\n",
    "    sev_score = 0\n",
    "    if sevs:\n",
    "        # pick the highest mapped severity\n",
    "        sev_score = max(sev_map.get(s, 0) for s in sevs)\n",
    "    breakdown[\"severity_list\"] = sevs\n",
    "    breakdown[\"severity_score\"] = sev_score\n",
    "    score += sev_score\n",
    "\n",
    "    # Malicious IPs\n",
    "    enrichment = threat_enrichment(entities, docs)\n",
    "    malicious_ips = enrichment.get(\"malicious_IPs\", [])\n",
    "    ip_score = 20 if malicious_ips else 0\n",
    "    breakdown[\"malicious_IPs\"] = malicious_ips\n",
    "    breakdown[\"malicious_ip_score\"] = ip_score\n",
    "    score += ip_score\n",
    "\n",
    "    # Powershell indicators (search docs + entity contexts)\n",
    "    combined_text = \" \".join([d.page_content for d in docs])\n",
    "    ps_present = any(tok.lower() in combined_text.lower() for tok in _powershell_indicators)\n",
    "    ps_score = 15 if ps_present else 0\n",
    "    breakdown[\"powershell_present\"] = ps_present\n",
    "    breakdown[\"powershell_score\"] = ps_score\n",
    "    score += ps_score\n",
    "\n",
    "    # brute-force indicators\n",
    "    bf_present = any(kw in combined_text.lower() for kw in _bruteforce_indicators)\n",
    "    bf_score = 15 if bf_present else 0\n",
    "    breakdown[\"bruteforce_present\"] = bf_present\n",
    "    breakdown[\"bruteforce_score\"] = bf_score\n",
    "    score += bf_score\n",
    "\n",
    "    # normalize / cap\n",
    "    final_score = min(100, int(score))\n",
    "    breakdown[\"raw_score\"] = score\n",
    "    breakdown[\"final_score\"] = final_score\n",
    "    return final_score, breakdown\n",
    "\n",
    "\n",
    "# --- Build enriched context Runnable for the chain ---\n",
    "def _build_enriched_context(q: str) -> dict:\n",
    "    # retrieve dense + sparse using the hybrid retriever\n",
    "    retrieved_docs = hybrid_retriever.invoke(q)\n",
    "    docs_text = \"\\n\\n---\\n\\n\".join([d.page_content for d in retrieved_docs])\n",
    "\n",
    "    # extract entities from query + retrieved docs\n",
    "    entities = extract_entities(q + \" \" + docs_text)\n",
    "\n",
    "    # enrichment + scoring\n",
    "    enrichment = threat_enrichment(entities, retrieved_docs)\n",
    "    score, breakdown = compute_threat_score(entities, retrieved_docs)\n",
    "\n",
    "    # compose a string context to feed the prompt\n",
    "    ctx = {\n",
    "        \"retrieved_snippets\": docs_text[:2000],\n",
    "        \"extracted_entities\": entities,\n",
    "        \"threat_enrichment\": enrichment,\n",
    "        \"threat_score\": score,\n",
    "        \"score_breakdown\": breakdown\n",
    "    }\n",
    "    # Return a mapping that matches the prompt's expected input variables\n",
    "    return {\n",
    "        \"context\": json.dumps(ctx, indent=2),\n",
    "        \"question\": q\n",
    "    }\n",
    "\n",
    "\n",
    "# override tool_chain to inject enriched context before the prompt runs\n",
    "tool_chain = (\n",
    "    RunnableLambda(_build_enriched_context)  # will receive the question string and return enriched context mapping\n",
    "    | prompt\n",
    "    | llm\n",
    "    | json_parser\n",
    ")\n",
    "\n",
    "\n",
    "# --- Updated caching-aware runner ---\n",
    "def get_kb_result(query: str):\n",
    "    key = cache_key(query)\n",
    "    cached_result = r.get(key)\n",
    "    if cached_result:\n",
    "        print(\"Cache hit!\")\n",
    "        try:\n",
    "            return json.loads(cached_result)\n",
    "        except Exception:\n",
    "            return cached_result\n",
    "\n",
    "    print(\"Cache miss! Running RAG chain (with enrichment & scoring).\")\n",
    "    result = tool_chain.invoke(query)\n",
    "\n",
    "    # ensure serializable and store as JSON\n",
    "    try:\n",
    "        out = result if isinstance(result, (dict, list)) else json.loads(str(result))\n",
    "    except Exception:\n",
    "        out = {\"raw\": str(result)}\n",
    "\n",
    "    r.set(key, json.dumps(out), ex=3600)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_response_with_cache(query: str):\n",
    "    return get_kb_result(query)\n",
    "\n",
    "\n",
    "# run example (keeps the same call pattern you had)\n",
    "response = get_response_with_cache(\"user_id='analyst500', query='Suspicious bound traffic detected from multiple hosts in the network'\")\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a6dcc086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit!\n",
      "Response:  {'recommended_resolution': 'Conduct a comprehensive network scan to identify and block suspicious IPs; Alert the network team for further investigation.', 'similar_past_incidents': [{'source': 'security_incidents.txt', 'snippet': 'Incident #034 | User=rakesh | Alert=Outbound traffic to known malicious IP | SourceIP=10.22.3.9 | Host=SRV-DB01 | OS=CentOS 7 | MITRE=T1071 | Severity=High | Resolution=Blocked traffic; Conducted IOC scan.'}, {'source': 'security_incidents.txt', 'snippet': 'Incident #012 | User=kishor | Alert=Detected network port scanning | SourceIP=172.22.9.54 | Host=SRV-WIN-02 | OS=Windows Server 2019 | MITRE=T1046 | Severity=High | Resolution=Blocked IP; Alerted network team.'}], 'entities': {'IPs': ['10.22.3.9', '172.22.9.54'], 'OS': ['Windows Server', 'CentOS', 'Windows'], 'Hostnames': ['SRV-DB01', 'SRV-WIN-02'], 'MITRE': ['T1046', 'T1071'], 'Severity': ['High']}, 'user_id': 'analyst500'}\n"
     ]
    }
   ],
   "source": [
    "response = get_response_with_cache(\"user_id='analyst500', query='Suspicious bound traffic detected from multiple hosts in the network'\")\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f30649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
